\documentclass{article}
\usepackage{graphicx,color,setspace,hyperref}
\usepackage{mathtools}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{listings}
\lstset{language=C}
\usepackage{pifont}% http://ctan.org/pkg/pifont
\newcommand{\cmark}{\(\checkmark\)}%
\newcommand{\xmark}{\ding{55}}%


\begin{document}

\title{Scale-out Bibliography}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Cloud Computing
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Cloud Computing}

\noindent\cite{zhang:journal2010-cloud-challenges} Challenges of cloud computing adn resource managements; Differences: SLOs and migration units; Similarities: map cloud resoruces to CPU and memory. \\

\noindent\cite{vilutis:ITI2012-cloud-load-balancing} Resource Provisioning - postpone tasking during peak traffic. \\

\noindent\cite{quiroz:grid2009-cloud-workload-provisioning} dynamic resource rescheduling in virtual machine environments - according to data center wide availability, load balancing, and constraints.\\

\noindent\cite{ranjan:cloud-computing2010-peer-to-peer} overview of current resource distribution mechanisms (CloudWatch, Eucalyptus, etc.).\\

\noindent\cite{gulati:hotcloud2011-cloud-resource-management} VMWare DRS, Challenges - discusses the modifiable ``knobs", challenges, and solutions in a cloud resource manager.\\

\noindent\cite{gulati:osdi2010-mclock} mClock: schedule IO for VMs with constraints and reservations. This is more difficult because storage is shared, locality is difficult, and because throughput varies. The solution is to logically interleave a constraint-based scheduler (overloaded) and a weight-based scheduler (priority).\\ 

\noindent\cite{xen-wlb} Xen WLB -  migrates VMs to balance load by maximizing performance or density; similare to SandPiper.\\

\noindent\cite{zaharia:hotcloud2011-datacenter-OS} Datacenter needs an OS - there are so many resources in a distributed setting that we need mechanisms for resource sharing (Mesos), data sharing (Spark), programming abstractions (RDDs, Mesos, MapReduce, Chubby), and debugging/monitoring (XTrace). \\

\section{Self-Tuning Systems}
\noindent\cite{padala:eurosys2009-autocontrol} AutoControl - online model estimator measures applications's resource usage and multi-in/output resource controller allocates resources.\\

\noindent\cite{wood:nsdi07-sandpiper} Sandpiper - migrates VMs to underloaded PMs; (physical resources \(\mapsto\) VMs)
Hotspot: if aggregate usage of any resource \(>\) thresh/SLA for ``sustained" period
\begin{itemize}
	\item profiler: tracks resources (CPU, network, and memory utilization)
	\begin{itemize}
		\item ``nucleus": server profiles (resource utilization over a sliding window)
		\begin{itemize}
			\item pr. distr. of the resource usage over W (i.e. usage variation; helps migration manager estimate peak resource requirements)
			\item time series of all observations in W (i.e. temporal fluctuations; helps hotspot detector to spot increasing utilization)
		\end{itemize}
	\end{itemize}
	\item hotspot detection: ``when to migrate VMs"
	\begin{itemize}
		\item trigger: (1) sustained utilization, (2) next predicted value\footnote{captures rising trends} \(>\) thresh
		\item grey box approaches can get more accurate peak utilization by reading application logs and perf counters (e.g., queueing theory for applications). 
	\end{itemize}
	\item migrator: ``what/where to migrate; how much to allocate after migration"
	\begin{itemize}
		\item orders available serves and assigns VMs, given the predicted utilization
		\item heuristic: minimize migration overhead (i.e. data transferred)
		\item volume = \(\Pi\frac{1}{1 - \text{rsrc}}\); ordered based on \(\frac{\text{vol}}{\text{size}}\) ratio to move the most load per byte
		\item match high VSR VM to low VSR PM; only move it CPU/network/memory can handle it
	\end{itemize}
\end{itemize}
Profiler
\begin{itemize}
	\item[\xmark] bottleneck at interval \(I\) for the control plane
	\item[\xmark] overhead of monitoring CPU?
\end{itemize}
Profiler
\begin{itemize}
	\item[\xmark] bytes per load is a good heuristic... what about resource per load?
\end{itemize}
Results: single server hotspots in \(< 20 s\); multi-server hotspots in minutes
\begin{itemize}
	\item load per byte is a good heuristic
	\item swaps have a lot of overhead but help mitigate hotspots
	\item responds to individual resources (switch network-bound w/ CPU-bound)
	\item black box can incorrectly move VMs
	\item microbenchmarks: overhead of computing placement (i.e. computing a new mapping of VMs to PMs is a NP-hard, so they approximate it with the VSR heuristic). 
\end{itemize}

\noindent\cite{} Cloud fault resilience - injected faults to different services at different points and observed (1) fault tolerance is not enabled by default, (2) timeouts are not supported, (3) it is difficult for layers to talk, and (4) external libraries can commingle.\\

%\noindent\cite{} IO Virtualization (waldspurger,rosenblum)- representative I/O system challenges. Conclusion is: virtual IO is a great tool with lotsa potential but it adds lotsa complexity, ambiguity, abstraction
%\begin{itemize}
%	\item benefits: (1) time/space multiplexing (less devices, higher utilization, device aggregation), (2) seamless migration/portability (across devices and OSSs), (3) flexibility (improve availability and balance load) and new features (transforming I/O requests, e.g., encryption)
%	\item challenges: performance (overhead traversing layers), quantifying ``nontrivial" penalties, how do we multiplex physical hardware across VMs of varying importance?, new algorithms to schedule requests fairly/efficiently (e.g., breaking TCP layer), security, customer expects good performance
%	\item approaches+: pluggable structure for back-end implementations, lower emulation cost (with traps, pass-thru modes), 
%\end{itemize}

%\noindent\cite{} Virtio: An I/O virtualization framework for Linux (tim jones) - interface for paravirtualized entities (i.e., modified guest OS and hypervisor) to communicate. \\
%Problem: full virtualization requires trap and emulate, which is inefficient\\
%Soln: virtio is an abstraction for common emulated devices in paravirtualizatyion, where you can implement block, network, pic, balloon and console drivers
%\begin{itemize}
%	\item QEMU: system emulator for the entire system
%	\item virtual queue interface: attach fe to be
%	\begin{itemize}
%		\item virtio device: configure the device
%		\item virtio queue: buffers for transmitting requests and data
%	\end{itemize}
%\end{itemize}

\noindent\cite{nadav:atc2011-viommu} vIOMMU: Efficient IOMMU emulation (*amit, yahuda, tasfiri, shcuster) - achieves direct device assignment for fully virtualized environments. \\
Motivation: we want DMA (access RAM independently of CPU) and direct device assignment for virtualized environments.\\
Problems: legacy DMA can't be used natively in virtualization, it lacks memory protection, and drivers cannot access entire memory; IOMMU is a piece of hardware that translates DMA addresses \(\rightarrow\) physical address\\
Problem (again): this has a number of shortcomings: (1) can't dynamically change RAM,  (2) no intra-guest protection between hypervisor and guest, (3) no redirection of DMA transactions
Soln: introduce a vIOMMU that multiplexes the IOMMU to remap pages in the hypervisor
\begin{enumerate}
	\item guest - IO device driver requests IO virtual address and updates mapping in PTEs and IOMMU TLB (which traps to IOMMU)
	\item IOMMU - reads emulated PTEs and translates guest to host address, then it pins the pages, and maps the physical pages, then it points to IO device driver
Advantages: finer control over memory pages (don't pin everything), intra-guest protection provided by IOMMU, inter-guest protection maintained
\end{enumerate}
Optimizations: VM exit and remapping is costly, so do side core emulation and save mappings optimistically. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% MapReduce Tweaks
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{MapReduce Tweaks}

\noindent\cite{buck:hpc2011-scihadoop} SciHadoop - improves the performance of MapReduce for array-based data and queries. Extensions allow the user to specify more information about the data so that the system can partition and retrieve data more efficiently.\\

\noindent\cite{bu:vldb2010-haloop} HaLoop - accommodates iterative tasks by introducing a new API, loop-aware task scheduling, caching loop-invariant data, and fixpoint evaluation caching.\\

\noindent\cite{ekanayake:hpdc2010-twister} Twister - accomodates iterative tasks by introducing a distributed in-memory cache, it extends the programming model to support ``broadcast" and ``scatter" type data transfers.\\

\noindent\cite{peng:osdi2010-percolator} Percolator - accomodates incremental updates and random access by implementing a library for BigTable operators that use observers, a timestamp oracle, lightweight locks, and notifications to leverage the indexing we've done previously.\\

\noindent\cite{ekanayake:escience2008-eglmapreduce} CGL-MapReduce - a streaming-based implementation the lets teh runtime use map/reduce tasks multiple times and can stream intermediate data to other components. They also show that with more data, the overhead of a the runtime diminishes.\\ 

\noindent\cite{gkantsidis:nsdi2013-rhea} Rhea - filters unstructured data so that less data is passed out on the wire. Achieved by doing some compile-time sorcery and determining what information is important for the computation.\\

\noindent\cite{cho:socc2013-natjam} Natjam - implements priority based eviction policies so that late-arriving high priority jobs can evict other jobs; employs CPU techniques.\\

\noindent\cite{mihailescu:hotstorage2012-mixapart} MixApart - introduces a cache layer so that compute tasks can be scheduled to overlay with data ingest; useful for the MapReduce workload characterizations (i.e. data reuse, CPU-bound input, predictable IO demands, etc.).\\

\subsection{Query Processing}

\noindent\cite{buck:sc2013-scidr} SIDR -  intelligently partitions and routes intermediate data, allowing it to: remove Hadoop's global barrier and execute Reduce tasks prior to all Map tasks completing; minimize intermediate key skew; and produce early, correct results.\\

\noindent\cite{balmin:sigmod2012-clydesdale} Clydesdale - accomodates structured data processing using high dimension star schemes, column-oriented layouts to interact with HDFS, and query processing sharing data structures.\\

\noindent\cite{elmore:sigmod2013-pythia} Pythia - database migration by learning tenant features and resource consumption. Templates are constructed and rules learned about which perform well together.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Other Distributed Runtimes
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Other Distributed Runtimes}

\noindent\cite{zaharia:nsdi2012-spark} Spark - accomodates iterative/interactive tasks by forcing the user to interact with RDDs (read-only, partitioned records) to manipulate and cache working-set data. The runtime manages coarse-grained lineage to control partitioning, ttrack lineage, schedule, compute on, and persist intermediate results.\\

\subsection{Query Processing}

\noindent\cite{engle:sigmod2012-shark} Shark - a query physical plan generator in Spark converts the Hive operator tree to operators that perform transformations on RDDs, which allows the runtime to optimize for	 inter/intra-quer locality.\\

\noindent\cite{melnik:vldb2010-dremel} Dremel - multi-level execution tree that stores relational data in a nested repreesentation, using a nested data model, server trees, and column-striped storage. This allows record-oriented storage, instead of record reconstruction, which can be run in parallel.\\


\section{Streaming}
\noindent\cite{rixner:2002-stream} Stream processing - introduces double buffering, shows the applicability for MapReduce.\\

\noindent\cite{neumeyer:icdmw2010-s4} S4 - creates a programing flow through the system, where processing elements (vertices) listen for events, forward to computation, and publish events; it processes stream data with a stream runtime that pipelines operations between computations\\

\noindent\cite{isard:EuroSys2007-dryad} Dryad - extended API for communciation DAG and per-vertex algorithms. The user iterativel manipulates the input and communication graphs to optimize perforamnce. It is more flexible than MapReduce because user can define data dependencies and many algorithms.\\
 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Performance/Benchmarking
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Performance}

\noindent\cite{fadika:cloud2012-evaluating-hadoop} Hadoop evaluation - ran HPC experiments on Hadoop and determined that tradeoffs for system configuration (file system, networking, replication, etc.) make a difference.\\

\noindent\cite{huang:icde2010-hibench} Hadoop Benchmark - set of Hadoop benchmarks (micro-benchmarks and real-world applications) to characterize speed, throughput, bandwidth, and system resources.\\

\noindent\cite{wisniewski:2007europar-commercial-scale-out} HPC Performance - scale-out performance is contingent on complex execution stack and many processes/threads per processing elem.\\

\noindent\cite{chen:2012ccpe-distributed-db} Distributed Databases - compares centralized, partitioned, and replicated databases.\\

\noindent\cite{chen:2011mascots-suites} Workload Suites - contends that benchmarks do not accurately simulate a real workload. They suggest sampling a trace to build a more realistic workload.\\

\noindent\cite{chen:2012vldb-cross-industry} Cross-Industry MR Study - in-depth study of MapReduce workloads. 90\% of all jobs are small; clusters are bursty and unpredictable and database functionalities are common.\\

\noindent\cite{wang:mascots2009-mrperf} MRPerf - modeling MapReduce using statistical analysis.\\

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Distributed Systems vs. Single Node
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Distributed Systems vs. Single Node}

\noindent\cite{appuswamy:socc2013-hadoop-vs-single-node} Scale-up vs. Scale-out for Hadoop - they compare single-node and distributed Hadoop because it (1) provides backwards compatibility, (2) keeps the applications portable, and (3) allows an apples to apples comparison.\\

\noindent\cite{michael:2007pdps-scale-up-x-scale-out} scaling comparison -  scale-out has a cost (resource utilization) and performance (4\(\times\)) advantage. \\

\noindent\cite{gigaspaces:whitepaper2011-su-vs-so} scaling comparison - we need to consider other scale-out properties and calls for an automated comparison process.\\

\noindent\cite{talkington:2002journal-scaling}	 scale-up is limited by processor/memory speeds and shared resource contention. Scale-out is limited by intra-node communication and workload management.\\

\noindent\cite{rowstron:hotcdp2012-hadoop-vs-single-node} Nobody ever got fired... - examines AdPredictor as a way to measure memory costs, job input sizes, implementation complexity, and performance.\\

\noindent\cite{appuswamy:techreport2013-hadoop-vs-single-node} Nobody ever got fired... - makes the claim that MapReduce jobs are often better served by a scale-up server for performance, \$, power, and server density. \\

\noindent\cite{schwarzkopf:hotcloud2012-7-sins} 7 Deadly Sins - common simplifications/shortcuts in cloud research are ``clouding" our analysis: unnecessary distributed data parallelism  (not all jobs are parallel), assuming performance homogeneity (poor methodology/result presentation), picking the low-hanging fruit (speedup over general Hadoop is not useful), forcing the abstraction (workload not big enough), unrepresentative workloads (should be running many jobs at once, not batch), perfect elasticity (limits to scalability/parallelism), ignoring fault tolerance (there is a cost).\\


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% HPC
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\noindent\cite{perez:jctc20150parsplice} ParSplice - molecular dynamics
simulator that uses a hybrid MD/AMD approach to get the best of both worlds:
fast simulation for uneventful persiods and exact simulations for rapid
transitions to new states. The novelty is speculation and segment splicing in
the AMD phase, and a model for determining when transitions occur.

%1. What is the problem the authors are trying to solve?
%
%Simulating atomic interactions in long-time dynamics with heterogenous
%barriers. Energy barriers are thresholds for when the system changes state;
%these transisitions have interesting events but the lull between causes
%problems for existing techniques.
%
%2. What other approaches or solutions existed at the time that this work was done?
%
%MD and AMD are two competing approaches to simulating atoms. MD is exact but
%only runs for short periods because the error explodes while AMD is highly
%parallel because it relaxes accuracy, instead opting for simulating
%state-to-state trajectory instead of per-molecule trajectories. ParRep is an
%AMD technique that uses statistics and parallelization by fuzzing the accuracy
%of simulations with similiar barriers (and thus longer state occupations).
%
%3. What was wrong with the other approaches or solutions?
%
%For running simulations with different barrier types, neither technique is
%sufficient. MD is too precise and the error nullifies the validity of the
%simulation. AMD does not offer enough accuracy for the interesting periods.`
%
%4. What is the authors' approach or solution?
%
%Using MD for state transitions and AMD for periods of innactivity.
%- inactivity modeled with segments, which are spliced from smaller segments
%- model for long term dynamics that pinpoints state transitions
%- meta-simulation to predict transitions to increase parallelism 
%
%Implementation
%- splicer: tries to make biggest segment
%  - coalesce existing segments, speculatively generate offset for P
%  - label states with connecitvity graphs to get a hash
%- producers: create segments given offset and act as a cache for requests
%  - use connective graphs to make DB rd/wr efficient
%
%5. Why is it better than the other approaches or solutions?
%
%ParSplice supports different accuracy (i.e. arbitrarily) for unstable states
%and performance can be optimioed if the metastable states/correlation times are
%known. It defeat the low barrier problem for long running dynamic simluations.
%
%6. How does it perform?
%
%Good?
%
%7. Why is this work important?
%
%Hybrid approach to MD and AMD that lets us use the resources of HPC via
%speculation, asynchornity, and fault model. The approach makes it feasible
%(correctness wise) and accurate enough to see what interesting events.
%
%8. 3+ comments/questions

\bibliographystyle{abbrv}
\bibliography{references}

\addcontentsline{toc}{section}{References} 

\newpage
\onecolumn
\appendix
%Appendix A
%\section{1}


\end{document}
