\section{Relation to Load Balancing}
\label{sec:relation-to-load-balancing}

In the previous section, we used our data management language and the Mantle
policy engine to design effective cache management strategies for a new service
and domain. In this section, we compare and contrast the policies examined for
file system metadata load balancing in~\cite{sevilla:sc15-mantle} with the ones
designed for cache management in ParSplice. The similarities show how the
``when"/``where"/``how much" abstractions, data anagement language, and policy
engine may be widely applicable to other data management techniques, such as
QoS, scheduling, and batching.

\subsection{File Systems}
From a high-level the ParSplice policy trims the cache if the cache reaches a
certain size {\it and} if it has already absorbed the initial burstiness of the
workload; the CephFS poicy, which is shown in Figure~\ref{srd:lua-cephfs},
migrates load if the metadata load is higher than the average load {\it and}
the current load has been overloaded for more than two iterations.

\textbf{Condition for ``Overloaded"} (Fig.~\ref{src:lru-dyn}: Line 2;
Fig.~\ref{lua:cephfs}: Line 2) - these lines detect whether the node is
overloaded using the ``load" calculated in the load callback; while the load
calculations and thresholds are different, the actual logic is exactly the
same.  Recall that this decision is made locally because there is no global
scheduler or centralized intelligence. 

\textbf{State Persisted Across Decisions} (Fig.~\ref{src:lru-dyn}: Lines 4,6;
Fig~\ref{lua:cephfs}: Lines 3,4,10) - these lines use Mantle to write/read state
from previous decisions.  For ParSplice, we save a boolean that indicates
whether we have absorbed the workload's initial burstiness. For CephFS, we save
the number of consecutive instances that the server has been overloaded. We
also clear the count (Line 10) if the server is no longer overloaded. The
underlying implementation saves the values to local disk.

\textbf{Condition that Switches Policy} (Fig.~\ref{src:lru-dyn}: Line 6;
Fig.~\ref{lua:cephfs}: Line 5) - these lines switch the policies using
information from previous decisions. ParSplice trims its cache once it eclipses
the ``absorb" threshold while CephFS allows balancing when overloaded for more
than two iterations. The persistent state is essential for both of these
policy-switching conditions.

\begin{figure}[t]
\footnotesize
\begin{minted}[xleftmargin=3em,linenos]{lua}
local function when()
  if servers[whoami]["load"] > target then
    overloaded = RDstate() + 1
    WRstate(overloaded)
    if overloaded > 2 then
      return true
    end
  end
  else then
    WRstate(0)
  end
  return false
end
\end{minted}
\caption{CephFS file system metadata load balancer.\label{lua:cephfs}}
\end{figure}

\begin{itemize}
  \item Lustre Trace
  \item LinkedIn Trace
  \item Nathan's Trace
\end{itemize}

\subsection{Using File System Policies for ParSplice}
% mantle policies
\subsection{Using ParSplice Policies for File Systems}
% burstiness of creates then compile

\subsection{Cross-pollinating Policies}
% QoS, MRC, RAD - scheduing
%\subsection{Visualizing File System Traces like ParSplice Keyspace Traces}

