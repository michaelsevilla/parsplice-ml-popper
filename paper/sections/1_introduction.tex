\section{Introduction}

The fine-grained data annotation capabilities provided by key-value storage is
a natural match for many types of scientific simulation. Simulations relying on
a mesh-based decomposition of a physical region may result in millions or
billions of mesh cells. Each cell contains materials, pressures, temperatures
and other characteristics that are required to accurately simulate phenomena of
interest. In our target application, the
ParSplice~\cite{perez:jctc20150parsplice} molecular dynamics simulation, a
hierarchy of cache nodes and a single node key-value store are used to store
both observed minima across a molecule's equation of motion (EOM) and the
hundreds or thousands of partial trajectories calculated each second during a
parallel job. Unfortunately, if we scale the system the IO to the storage
hierarchy will quickly saturate both the storage and bandwidth capacity of a
single node. 

In this paper we present a detailed analysis of how the ParSplice application
accesses key-value pairs over the course of a long running simulation across a
variety of initial conditions. We reason that limiting the size of a cache on a
single node saves memory and sacrifices negligible performance. This type of
analysis (1) shows the capacity and resource requirements of a single node and
(2) will help inform our load balancing policies for when we switch to a
distributed key-value store back-end to store EOM minima. We need to know when
and how to partition the keyspace: a smaller cache hurts performance because
key-value pairs need to be retrieved from other nodes while a larger cache has
higher memory pressure.

% What is Mantle
To explore the effects of different cache management strategies, we link the
Mantle policy engine into ParSplice~\cite{perez:jctc20150parsplice}.
Developers write policies for ``when" they want data moved, ``where" they want
data moved, and ``how much" of the data to move and the framework executes
these policies whenever a decision needs to be made.  This abstraction helps
developers unfamiliar with the domain quickly reason about, develop, and deploy
new policies that control temporal and spatial locality.  It has already proven
to be a critical control plane for improving file system metadata load
balancing~\cite{sevilla:sc15-mantle} and in this work we show its usefulness in
cache management for the changing key-value workloads generated by ParSplice. 

% What are we going to show
We show how Mantle:
\begin{itemize}

  \item decomposes cache management into independent policies that can be
  dynamically changed, making the problem more manageable and facilitating rapid
  development. Changing the policy in use is critical in applications such as
  ParSplice that have alternating stable and chaotic simulation ``access regimes"
  over the course of a long-running simulation.  

  \item has useful primitives that, while designed for file systems, turn
  out to also be effective for cache management. This finding shows how the Mantle
  engine generalizes to a different domain and code-base.

  \item can be used to quickly deploy a variety of cache management strategies,
  ranging from basic algorithms and heuristics to statistical models and machine
  learning.

\end{itemize}

% this gives us many policies that are effective across disciplines
% - reuse: eases burden of writing policies
% - autonomic: lays groundwork for an adaptable policy that mixes/matches policies

This last contribution is explored in Section~\S\ref{sec:mantle-brains}, where
we try a range of policies from different disciplines; but more importantly, in
Section~\S\ref{sec:relation-to-file-systems}, we conclude that the collection
of policies we designed for ParSplice's cache management are very similar to
the policies implemented in the Ceph file system metadata load balancer. This
lays the foundation for future work, where we will focus on formalizing a
collection of general data management policies that can be used across domains
and services. The value of such a collection eases the burden of policy
development and paves the way for solutions that remove the administrator from
the development cycle, such as (1) adaptable policies that automatically switch
to new strategies when the current strategy behaves poorly ({e.g.}, thrashing,
making no progress, etc.), and (2) policy generation, where new policies are
constructed automatically by examining the collection of existing policies.
Such work is made possible with Mantle's ability to dynamically change
policies.

%First, we implement the ``how much" abstraction as an LRU and then we focus on
%the ``when" abstraction. 
%Manageable: abstracts away complexities of the system (pass around to others,
%use different strategies) 

